{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR0FkB4Ct-X_"
      },
      "source": [
        "# Playing with model editing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/dgcnz/development/uva/fact/FACT\n",
            "LICENSE                               \u001b[34mmodels\u001b[m\u001b[m/\n",
            "README.md                             \u001b[34mnotebook\u001b[m\u001b[m/\n",
            "accuracies.csv                        \u001b[34mnotebooks\u001b[m\u001b[m/\n",
            "accuracies2.csv                       \u001b[34mold_logs\u001b[m\u001b[m/\n",
            "\u001b[34martifacts\u001b[m\u001b[m/                            poetry.lock\n",
            "\u001b[34massets\u001b[m\u001b[m/                               pyproject.toml\n",
            "\u001b[34mconcepts\u001b[m\u001b[m/                             \u001b[34mscripts\u001b[m\u001b[m/\n",
            "\u001b[34mconfigs\u001b[m\u001b[m/                              \u001b[34mslurm\u001b[m\u001b[m/\n",
            "\u001b[34mdata\u001b[m\u001b[m/                                 test_cav_activation.py\n",
            "debug.log                             test_different_projections.py\n",
            "\u001b[34mdocs\u001b[m\u001b[m/                                 testnotebook.ipynb\n",
            "environment.yaml                      train_pcbm.py\n",
            "evaluate_og_model.py                  train_pcbm_h.py\n",
            "\u001b[34mexperiments\u001b[m\u001b[m/                          train_pcbm_userstudy.py\n",
            "\u001b[34mextension_scripts\u001b[m\u001b[m/                    \u001b[34mtraining_tools\u001b[m\u001b[m/\n",
            "learn_concepts_dataset.py             verify_clip_pcbm_h.py\n",
            "learn_concepts_multimodal.py          verify_dataset_pcbm.py\n",
            "\u001b[34mlightning_logs\u001b[m\u001b[m/                       verify_dataset_pcbm_h.py\n",
            "\u001b[34mlogs\u001b[m\u001b[m/                                 verify_results_clip_concepts_pcbm.py\n",
            "model_editing.out\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "if Path().resolve().name == \"notebooks\":\n",
        "    %cd ..\n",
        "%ls\n",
        "import sys\n",
        "sys.path.append(\"models\")\n",
        "sys.path.append(\"data\")\n",
        "sys.path.append(\"concepts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from models import PosthocLinearCBM, get_model\n",
        "from collections import namedtuple\n",
        "from data import get_dataset\n",
        "from concepts import ConceptBank\n",
        "import pickle\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bank path: artifacts/outdir/broden_clip_RN50_10.0_50.pkl. 170 concepts will be used.\n",
            "Concept Bank is initialized.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "BACKBONE_NAME = \"clip:RN50\"\n",
        "DEVICE = \"cpu\"\n",
        "CONCEPT_BANK = \"artifacts/outdir/broden_clip_RN50_10.0_50.pkl\"\n",
        "PCBM_PATH = \"artifacts/outdir/pcbm_cifar10__clip_RN50__broden_clip_RN50_10__lam_0.0002__alpha_0.99__seed_42.ckpt\"\n",
        "args = namedtuple(\n",
        "    \"Args\",\n",
        "    [\n",
        "        \"out_dir\",\n",
        "        \"device\",\n",
        "        \"dataset\",\n",
        "        \"batch_size\",\n",
        "        \"num_workers\",\n",
        "    ],\n",
        ")(\n",
        "    out_dir=\"artifacts/outdir\",\n",
        "    device=DEVICE,\n",
        "    dataset=\"cifar10\",\n",
        "    batch_size=64,\n",
        "    num_workers=4,\n",
        ")\n",
        "all_concepts = pickle.load(open(CONCEPT_BANK, 'rb'))\n",
        "all_concept_names = list(all_concepts.keys())\n",
        "print(f\"Bank path: {CONCEPT_BANK}. {len(all_concept_names)} concepts will be used.\")\n",
        "concept_bank = ConceptBank(all_concepts, args.device)\n",
        "backbone, preprocess = get_model(args, backbone_name=BACKBONE_NAME)\n",
        "train_loader, test_loader, idx_to_class, classes = get_dataset(args, preprocess)\n",
        "num_classes = len(classes)\n",
        "backbone = backbone.to(DEVICE)\n",
        "backbone.eval()\n",
        "# posthoc_layer = PosthocLinearCBM(\n",
        "#     concept_bank,\n",
        "#     backbone_name=BACKBONE_NAME,\n",
        "#     idx_to_class=idx_to_class,\n",
        "#     n_classes=num_classes,\n",
        "# )\n",
        "# posthoc_layer = posthoc_layer.to(args.device)\n",
        "posthoc_layer = torch.load(PCBM_PATH, map_location=torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "170\n"
          ]
        }
      ],
      "source": [
        "print(len(concept_bank.concept_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concept_bank.concept_info.concept_names.index(\"dog\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "concept_bank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d = dict(zip(concept_bank.concept_names, list(range(len(concept_bank.concept_names)))))\n",
        "d[\"dog\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d[\"cat\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['door_frame',\n",
              " 'concrete',\n",
              " 'horse',\n",
              " 'food',\n",
              " 'oven',\n",
              " 'mouse',\n",
              " 'bedroom_s',\n",
              " 'book',\n",
              " 'chain_wheel',\n",
              " 'blueness']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(d.keys())[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'airplane',\n",
              " 1: 'automobile',\n",
              " 2: 'bird',\n",
              " 3: 'cat',\n",
              " 4: 'deer',\n",
              " 5: 'dog',\n",
              " 6: 'frog',\n",
              " 7: 'horse',\n",
              " 8: 'ship',\n",
              " 9: 'truck'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx_to_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 1024)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_concepts[\"door_frame\"][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_concepts[\"\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PosthocLinearCBM(\n",
              "  (classifier): Linear(in_features=170, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "posthoc_layer.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 170])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "posthoc_layer.classifier.weight.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Class : airplane',\n",
              " '\\t 1 - airplane: 13.058',\n",
              " '\\t 2 - body: 5.333',\n",
              " '\\t 3 - bench: 5.237',\n",
              " '\\t 4 - fluorescent: 5.024',\n",
              " '\\t 5 - building: 4.217',\n",
              " 'Class : automobile',\n",
              " '\\t 1 - headlight: 13.475',\n",
              " '\\t 2 - car: 7.165',\n",
              " '\\t 3 - door: 4.991',\n",
              " '\\t 4 - flower: 3.321',\n",
              " '\\t 5 - motorbike: 3.272',\n",
              " 'Class : bird',\n",
              " '\\t 1 - bird: 9.885',\n",
              " '\\t 2 - house: 7.090',\n",
              " '\\t 3 - foot: 6.455',\n",
              " '\\t 4 - ashcan: 4.173',\n",
              " '\\t 5 - handle_bar: 3.579',\n",
              " 'Class : cat',\n",
              " '\\t 1 - cat: 9.937',\n",
              " '\\t 2 - foot: 6.573',\n",
              " '\\t 3 - floor: 6.013',\n",
              " '\\t 4 - street_s: 4.118',\n",
              " '\\t 5 - ceramic: 3.946',\n",
              " 'Class : deer',\n",
              " '\\t 1 - street_s: 8.018',\n",
              " '\\t 2 - tree: 6.953',\n",
              " '\\t 3 - engine: 6.178',\n",
              " '\\t 4 - clock: 5.866',\n",
              " '\\t 5 - pipe: 5.183',\n",
              " 'Class : dog',\n",
              " '\\t 1 - paw: 8.105',\n",
              " '\\t 2 - muzzle: 6.343',\n",
              " '\\t 3 - board: 6.019',\n",
              " '\\t 4 - exhaust_hood: 5.522',\n",
              " '\\t 5 - keyboard: 5.193',\n",
              " 'Class : frog',\n",
              " '\\t 1 - hand: 6.303',\n",
              " '\\t 2 - greenness: 6.221',\n",
              " '\\t 3 - food: 4.601',\n",
              " '\\t 4 - carpet: 4.462',\n",
              " '\\t 5 - pipe: 4.129',\n",
              " 'Class : horse',\n",
              " '\\t 1 - horse: 8.484',\n",
              " '\\t 2 - building: 6.793',\n",
              " '\\t 3 - bucket: 4.013',\n",
              " '\\t 4 - headboard: 3.812',\n",
              " '\\t 5 - hand: 3.763',\n",
              " 'Class : ship',\n",
              " '\\t 1 - water: 6.174',\n",
              " '\\t 2 - basket: 5.461',\n",
              " '\\t 3 - chest_of_drawers: 5.299',\n",
              " '\\t 4 - desk: 4.303',\n",
              " '\\t 5 - laminate: 4.194',\n",
              " 'Class : truck',\n",
              " '\\t 1 - can: 5.840',\n",
              " '\\t 2 - headboard: 5.174',\n",
              " '\\t 3 - pedestal: 4.189',\n",
              " '\\t 4 - field: 4.028',\n",
              " '\\t 5 - chain_wheel: 3.747']"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "posthoc_layer.analyze_classifier().split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from models.pcbm_pl import PCBMClassifierTrainer\n",
        "from lightning import Trainer\n",
        "from data.metashift import MetaShiftDataModule, PreprocessorEnum\n",
        "from data.metashift import NNProjector\n",
        "from models.clip_encoder import CLIPImageEncoder\n",
        "from lightning.pytorch import seed_everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "ckpt_path = \"lightning_logs/task_1_bed_cat_dog/seed_42/version_0/checkpoints/epoch=19-step=1260.ckpt\"\n",
        "pcbm = PCBMClassifierTrainer.load_from_checkpoint(ckpt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Concept Bank is initialized.\n"
          ]
        }
      ],
      "source": [
        "metashift = MetaShiftDataModule(\n",
        "    task_name=\"task_1_bed_cat_dog\",\n",
        "    projector=NNProjector(\n",
        "        concept_bank_path=\"artifacts/outdir/broden_clip_RN50_10.0_50.pkl\",\n",
        "        backbone=CLIPImageEncoder(model_name=\"RN50\"),\n",
        "    ),\n",
        "    preprocessor_name=PreprocessorEnum.CLIP_RESNET50,\n",
        "    train_batch_size=16,\n",
        "    test_batch_size=64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ClassLabel(names=['airplane', 'bed', 'car', 'cow', 'keyboard'], id=None)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metashift.dataset[\"train\"].info.features[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(deterministic=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f0fa7c02fd94768905ba38ef28f5dc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/dgcnz/development/uva/fact/FACT/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51f895c1323047c1abfded60925bf813",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9139999747276306     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9139999747276306    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'test_accuracy': 0.9139999747276306}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed_everything(42)\n",
        "trainer.test(pcbm, metashift)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#   pruned_concept_class_pairs:\n",
        "#     - [128, 1]\n",
        "pcbm_pruned = PCBMClassifierTrainer.load_from_checkpoint(ckpt_path, pruned_concept_class_pairs=[(128, 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-1.8379e-01, -1.4750e+00, -7.9499e-01, -8.7337e-01,  4.6112e-01,\n",
              "        -1.2257e+00, -1.1098e+00,  2.7706e+00, -2.7329e-01, -6.3556e-01,\n",
              "         8.7478e-01,  4.0155e-01,  5.9591e-02,  2.5387e-01, -5.3535e-01,\n",
              "         1.2156e+00, -3.9201e-01,  1.1857e+00,  1.4236e+00,  3.4622e+00,\n",
              "         1.0951e-01, -1.3728e-01, -2.7274e-01, -6.8375e-02, -2.1637e+00,\n",
              "        -6.9077e-01,  3.4282e+00,  1.8606e+00, -9.9328e-01, -1.3042e+00,\n",
              "        -1.8206e+00, -3.2627e-03, -1.1488e+00,  2.7601e+00, -3.9218e+00,\n",
              "         1.4030e-01,  1.6988e+00, -3.8362e-01,  1.7959e+00, -1.2532e+00,\n",
              "        -4.5289e-01, -6.5062e-01,  1.1795e-01, -1.7453e+00, -6.2271e-01,\n",
              "         1.7091e+00, -1.3507e+00,  2.0358e+00, -1.7186e+00,  1.2518e+00,\n",
              "        -1.0837e+00, -2.4383e+00,  4.6233e-01,  2.5421e-01,  1.6956e+00,\n",
              "         2.0141e+00, -1.7333e+00, -2.3271e+00, -1.6009e+00, -1.8261e+00,\n",
              "        -9.5668e-01, -1.9399e+00, -1.3950e+00,  1.3293e+00,  1.0415e+00,\n",
              "        -3.6348e-01,  1.1920e+00,  9.7176e-01,  1.1846e+00, -9.9544e-02,\n",
              "        -1.2311e+00,  8.7118e-02,  9.4055e-01, -5.0039e-03, -5.3475e-01,\n",
              "         9.2594e-01, -1.8367e+00,  2.3676e-01,  2.4398e+00,  2.7327e+00,\n",
              "         1.6105e-01, -3.5314e-02,  9.1271e-02,  7.5874e-01,  1.3314e+00,\n",
              "        -1.1143e-02,  2.5148e+00,  6.8121e-01,  1.2198e+00, -1.6809e+00,\n",
              "        -5.6395e-01,  2.4702e-02, -9.8967e-01, -2.3263e+00,  2.0724e-01,\n",
              "         2.0711e-01, -7.9916e-01, -2.7045e-01, -7.6308e-01, -3.6629e+00,\n",
              "         4.2980e-01,  6.1394e-01, -1.1735e-02, -1.3604e+00,  9.5940e-01,\n",
              "        -2.8786e-01, -2.2094e-01, -3.6269e-01, -6.3270e-01,  1.8698e+00,\n",
              "         1.6230e+00,  1.5792e-01, -1.2907e+00,  1.8487e+00, -8.3317e-01,\n",
              "         2.1575e+00, -8.7889e-01,  7.6723e-01,  1.4317e+00, -3.9323e-01,\n",
              "        -1.9102e+00,  1.4766e+00, -9.7838e-01,  2.3347e+00,  4.2424e+00,\n",
              "         1.9017e+00, -6.0414e-01,  1.1005e+00,  0.0000e+00,  2.2208e-01,\n",
              "        -2.7023e-02,  1.7916e+00,  7.1076e-01, -2.3125e+00,  1.1241e+00,\n",
              "         1.8155e-01,  1.7494e+00,  5.5551e-01, -1.1644e+00,  1.7888e+00,\n",
              "         1.4352e+00, -8.2021e-01,  1.0398e+00, -8.0963e-02,  1.8162e+00,\n",
              "        -1.7966e-01,  4.4647e+00, -2.7707e+00,  4.7230e-01,  1.2397e+00,\n",
              "        -2.2981e+00,  4.2740e-01,  5.9469e-01, -8.7792e-01, -8.2364e-01,\n",
              "        -1.4984e+00, -1.1580e+00, -1.3220e+00,  6.5489e-01, -1.8617e-01,\n",
              "        -2.0268e+00, -9.7519e-01,  2.3210e+00, -3.7666e-01,  2.9855e-01,\n",
              "         2.9712e+00,  3.9574e-01,  2.9977e+00, -1.8716e-01, -7.0114e-01],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcbm_pruned.model.classifier.weight[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-1.8379e-01, -1.4750e+00, -7.9499e-01, -8.7337e-01,  4.6112e-01,\n",
              "        -1.2257e+00, -1.1098e+00,  2.7706e+00, -2.7329e-01, -6.3556e-01,\n",
              "         8.7478e-01,  4.0155e-01,  5.9591e-02,  2.5387e-01, -5.3535e-01,\n",
              "         1.2156e+00, -3.9201e-01,  1.1857e+00,  1.4236e+00,  3.4622e+00,\n",
              "         1.0951e-01, -1.3728e-01, -2.7274e-01, -6.8375e-02, -2.1637e+00,\n",
              "        -6.9077e-01,  3.4282e+00,  1.8606e+00, -9.9328e-01, -1.3042e+00,\n",
              "        -1.8206e+00, -3.2627e-03, -1.1488e+00,  2.7601e+00, -3.9218e+00,\n",
              "         1.4030e-01,  1.6988e+00, -3.8362e-01,  1.7959e+00, -1.2532e+00,\n",
              "        -4.5289e-01, -6.5062e-01,  1.1795e-01, -1.7453e+00, -6.2271e-01,\n",
              "         1.7091e+00, -1.3507e+00,  2.0358e+00, -1.7186e+00,  1.2518e+00,\n",
              "        -1.0837e+00, -2.4383e+00,  4.6233e-01,  2.5421e-01,  1.6956e+00,\n",
              "         2.0141e+00, -1.7333e+00, -2.3271e+00, -1.6009e+00, -1.8261e+00,\n",
              "        -9.5668e-01, -1.9399e+00, -1.3950e+00,  1.3293e+00,  1.0415e+00,\n",
              "        -3.6348e-01,  1.1920e+00,  9.7176e-01,  1.1846e+00, -9.9544e-02,\n",
              "        -1.2311e+00,  8.7118e-02,  9.4055e-01, -5.0039e-03, -5.3475e-01,\n",
              "         9.2594e-01, -1.8367e+00,  2.3676e-01,  2.4398e+00,  2.7327e+00,\n",
              "         1.6105e-01, -3.5314e-02,  9.1271e-02,  7.5874e-01,  1.3314e+00,\n",
              "        -1.1143e-02,  2.5148e+00,  6.8121e-01,  1.2198e+00, -1.6809e+00,\n",
              "        -5.6395e-01,  2.4702e-02, -9.8967e-01, -2.3263e+00,  2.0724e-01,\n",
              "         2.0711e-01, -7.9916e-01, -2.7045e-01, -7.6308e-01, -3.6629e+00,\n",
              "         4.2980e-01,  6.1394e-01, -1.1735e-02, -1.3604e+00,  9.5940e-01,\n",
              "        -2.8786e-01, -2.2094e-01, -3.6269e-01, -6.3270e-01,  1.8698e+00,\n",
              "         1.6230e+00,  1.5792e-01, -1.2907e+00,  1.8487e+00, -8.3317e-01,\n",
              "         2.1575e+00, -8.7889e-01,  7.6723e-01,  1.4317e+00, -3.9323e-01,\n",
              "        -1.9102e+00,  1.4766e+00, -9.7838e-01,  2.3347e+00,  4.2424e+00,\n",
              "         1.9017e+00, -6.0414e-01,  1.1005e+00,  1.9985e+00,  2.2208e-01,\n",
              "        -2.7023e-02,  1.7916e+00,  7.1076e-01, -2.3125e+00,  1.1241e+00,\n",
              "         1.8155e-01,  1.7494e+00,  5.5551e-01, -1.1644e+00,  1.7888e+00,\n",
              "         1.4352e+00, -8.2021e-01,  1.0398e+00, -8.0963e-02,  1.8162e+00,\n",
              "        -1.7966e-01,  4.4647e+00, -2.7707e+00,  4.7230e-01,  1.2397e+00,\n",
              "        -2.2981e+00,  4.2740e-01,  5.9469e-01, -8.7792e-01, -8.2364e-01,\n",
              "        -1.4984e+00, -1.1580e+00, -1.3220e+00,  6.5489e-01, -1.8617e-01,\n",
              "        -2.0268e+00, -9.7519e-01,  2.3210e+00, -3.7666e-01,  2.9855e-01,\n",
              "         2.9712e+00,  3.9574e-01,  2.9977e+00, -1.8716e-01, -7.0114e-01],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcbm.model.classifier.weight[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.9985, grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcbm.model.classifier.weight[1][128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0., device='mps:0', grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcbm_pruned.model.classifier.weight[1][128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4794074419b4481fa12d884c1d0358f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dd9a47e35134e78b76a0cb340f96c5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9139999747276306     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9139999747276306    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'test_accuracy': 0.9139999747276306}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed_everything(42)\n",
        "trainer.test(pcbm_pruned, metashift)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "pcbm_trainer = PCBMClassifierTrainer(n_concepts=170, n_classes=5, lr=0.05, lam=0.05, alpha=0.99)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "seed_everything(42)\n",
        "trainer = Trainer(deterministic=True, max_epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 100\n",
            "\n",
            "  | Name  | Type           | Params\n",
            "-----------------------------------------\n",
            "0 | model | PCBMClassifier | 855   \n",
            "1 | loss  | PCBMLoss       | 855   \n",
            "-----------------------------------------\n",
            "855       Trainable params\n",
            "0         Non-trainable params\n",
            "855       Total params\n",
            "0.003     Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1eef6bef45394ac68c2f67ee858547ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
          ]
        }
      ],
      "source": [
        "seed_everything(seed)\n",
        "trainer.fit(pcbm_trainer, metashift)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 100\n",
            "/Users/dgcnz/development/uva/fact/FACT/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f420e5ea441949d2bf83cf151363687e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8939999938011169     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8939999938011169    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "seed_everything(seed)\n",
        "out = trainer.test(pcbm_trainer, metashift)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'test_accuracy': 0.8939999938011169}]\n"
          ]
        }
      ],
      "source": [
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/dgcnz/development/uva/fact/FACT/lightning_logs/version_1/checkpoints/epoch=29-step=960.ckpt'"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.checkpoint_callback.best_model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "pcbm_trainer_pruned = PCBMClassifierTrainer.load_from_checkpoint(trainer.checkpoint_callback.best_model_path,\n",
        "                                                          pruned_concept_class_pairs=[(128, 1)]\n",
        "                                                         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0., device='mps:0', grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcbm_trainer_pruned.model.classifier.weight[1, 128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.2930, grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcbm_trainer.model.classifier.weight[1, 128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 100\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1dc50fa0b7eb42a5b3c17290053c1995",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8980000019073486     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8980000019073486    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "seed_everything(seed)\n",
        "pruned_out = trainer.test(pcbm_trainer_pruned, metashift)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'test_accuracy': 0.8980000019073486}]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pruned_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0040000081062316895"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pruned_out[-1][\"test_accuracy\"] - out[-1][\"test_accuracy\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lightning_logs/task_1_bed_dog_cat/seed_42/version_6/checkpoints/epoch=19-step=640.ckpt\n"
          ]
        }
      ],
      "source": [
        "path = Path(\"lightning_logs/task_1_bed_dog_cat/seed_42/version_6/checkpoints/epoch=19-step=640.ckpt\")\n",
        "print(path)\n",
        "pcbm = PCBMClassifierTrainer.load_from_checkpoint(str(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from models.pcbm_pl import analyze_classifier\n",
        "from models.resnet import ResNet18FeatureExtractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Concept Bank is initialized.\n"
          ]
        }
      ],
      "source": [
        "CONCEPT_BANK = \"artifacts/outdir/broden_resnet18_imagenet1k_v1_0.1_50.pkl\"\n",
        "all_concepts = pickle.load(open(CONCEPT_BANK, 'rb'))\n",
        "all_concept_names = list(all_concepts.keys())\n",
        "concept_bank = ConceptBank(all_concepts, args.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Concept Bank is initialized.\n"
          ]
        }
      ],
      "source": [
        "metashift_resnet18 = MetaShiftDataModule(\n",
        "    task_name=\"task_1_bed_dog_cat\",\n",
        "    projector=NNProjector(\n",
        "        concept_bank_path=\"artifacts/outdir/broden_resnet18_imagenet1k_v1_0.1_50.pkl\",\n",
        "        backbone=ResNet18FeatureExtractor(),\n",
        "    ),\n",
        "    preprocessor_name=PreprocessorEnum.RESNET18_IMAGENET_1K_V1,\n",
        "    train_batch_size=16,\n",
        "    test_batch_size=64\n",
        ")\n",
        "metashift_resnet18.setup(\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Concept Bank is initialized.\n"
          ]
        }
      ],
      "source": [
        "metashift_resnet50 = MetaShiftDataModule(\n",
        "    task_name=\"task_1_bed_dog_cat\",\n",
        "    projector=NNProjector(\n",
        "        concept_bank_path=\"artifacts/outdir/broden_clip_RN50_10.0_50.pkl\",\n",
        "        backbone=CLIPImageEncoder(model_name=\"RN50\"),\n",
        "    ),\n",
        "    preprocessor_name=PreprocessorEnum.CLIP_RESNET50,\n",
        "    train_batch_size=16,\n",
        "    test_batch_size=64\n",
        ")\n",
        "metashift_resnet50.setup(\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pickle\n",
        "with open(\"artifacts/outdir/broden_clip_RN50_10.0_50.pkl\", \"rb\") as f:\n",
        "    concept_dict = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n",
            "72\n",
            "30\n"
          ]
        }
      ],
      "source": [
        "cons = [\"cat\", \"dog\", \"book\"]\n",
        "for con in cons:\n",
        "    print(metashift_resnet18.projector.concept_names.index(con))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n",
            "72\n",
            "30\n"
          ]
        }
      ],
      "source": [
        "for con in cons:\n",
        "    print(metashift_resnet50.projector.concept_names.index(con))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-0.3531, device='mps:0', grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcbm.model.classifier.weight[1, 72]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class : airplane\n",
            "\t 1 - jar: 2.947\n",
            "\t 2 - pillow: 1.865\n",
            "\t 3 - ceramic: 1.854\n",
            "\t 4 - hair: 1.734\n",
            "\t 5 - paper: 1.538\n",
            "Class : bed\n",
            "\t 1 - mouse: 2.838\n",
            "\t 2 - clock: 2.642\n",
            "\t 3 - bus: 2.136\n",
            "\t 4 - balcony: 1.924\n",
            "\t 5 - bicycle: 1.461\n",
            "Class : car\n",
            "\t 1 - handle: 1.552\n",
            "\t 2 - chandelier: 1.310\n",
            "\t 3 - headlight: 1.309\n",
            "\t 4 - bench: 1.294\n",
            "\t 5 - fireplace: 1.251\n",
            "Class : cow\n",
            "\t 1 - redness: 1.824\n",
            "\t 2 - field: 1.820\n",
            "\t 3 - bird: 1.780\n",
            "\t 4 - bedclothes: 1.732\n",
            "\t 5 - minibike: 1.701\n",
            "Class : keyboard\n",
            "\t 1 - sofa: 2.877\n",
            "\t 2 - laminate: 2.399\n",
            "\t 3 - bicycle: 2.219\n",
            "\t 4 - blotchy: 1.948\n",
            "\t 5 - air_conditioner: 1.788\n"
          ]
        }
      ],
      "source": [
        "s =analyze_classifier(\n",
        "    pcbm.model,\n",
        "    concept_names=metashift_resnet18.projector.concept_names,\n",
        "    class_names=metashift_resnet18.dataset[\"train\"].info.features[\"label\"].names,\n",
        ")\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['cat',\n",
              " 'paper',\n",
              " 'apron',\n",
              " 'microwave',\n",
              " 'tree',\n",
              " 'pane',\n",
              " 'lamp',\n",
              " 'polka_dots',\n",
              " 'flowerpot',\n",
              " 'fluorescent',\n",
              " 'hand',\n",
              " 'drawer',\n",
              " 'fireplace',\n",
              " 'figurine',\n",
              " 'blind',\n",
              " 'bench',\n",
              " 'basket',\n",
              " 'footboard',\n",
              " 'chandelier',\n",
              " 'handle_bar',\n",
              " 'flag',\n",
              " 'bedclothes',\n",
              " 'drinking_glass',\n",
              " 'car',\n",
              " 'chain_wheel',\n",
              " 'can',\n",
              " 'balcony',\n",
              " 'eye',\n",
              " 'bed',\n",
              " 'pipe',\n",
              " 'box',\n",
              " 'cup',\n",
              " 'manhole',\n",
              " 'granite',\n",
              " 'desk',\n",
              " 'back',\n",
              " 'greenness',\n",
              " 'cushion',\n",
              " 'ceramic',\n",
              " 'water',\n",
              " 'dog',\n",
              " 'plant',\n",
              " 'board',\n",
              " 'handle',\n",
              " 'metal',\n",
              " 'foot',\n",
              " 'concrete',\n",
              " 'armchair',\n",
              " 'curtain',\n",
              " 'ground',\n",
              " 'person',\n",
              " 'pedestal',\n",
              " 'grass',\n",
              " 'stripes',\n",
              " 'flower',\n",
              " 'bridge',\n",
              " 'ottoman',\n",
              " 'blotchy',\n",
              " 'redness',\n",
              " 'coffee_table',\n",
              " 'path',\n",
              " 'cardboard',\n",
              " 'cabinet',\n",
              " 'laminate',\n",
              " 'jar',\n",
              " 'body',\n",
              " 'outside_arm',\n",
              " 'oven',\n",
              " 'pack',\n",
              " 'chair',\n",
              " 'exhaust_hood',\n",
              " 'napkin',\n",
              " 'paw',\n",
              " 'bus',\n",
              " 'chest_of_drawers',\n",
              " 'hill',\n",
              " 'plate',\n",
              " 'frame',\n",
              " 'nose',\n",
              " 'mouth',\n",
              " 'column',\n",
              " 'doorframe',\n",
              " 'headlight',\n",
              " 'loudspeaker',\n",
              " 'motorbike',\n",
              " 'inside_arm',\n",
              " 'pillar',\n",
              " 'double_door',\n",
              " 'carpet',\n",
              " 'field',\n",
              " 'dining_room_s',\n",
              " 'mouse',\n",
              " 'ear',\n",
              " 'bookcase',\n",
              " 'head',\n",
              " 'countertop',\n",
              " 'ceiling',\n",
              " 'coach',\n",
              " 'air_conditioner',\n",
              " 'toilet',\n",
              " 'glass',\n",
              " 'headboard',\n",
              " 'cap',\n",
              " 'painted',\n",
              " 'pillow',\n",
              " 'sofa',\n",
              " 'bowl',\n",
              " 'painting',\n",
              " 'bucket',\n",
              " 'bird',\n",
              " 'lid',\n",
              " 'earth',\n",
              " 'fence',\n",
              " 'chimney',\n",
              " 'bathroom_s',\n",
              " 'brick',\n",
              " 'minibike',\n",
              " 'airplane',\n",
              " 'awning',\n",
              " 'food',\n",
              " 'book',\n",
              " 'candlestick',\n",
              " 'leg',\n",
              " 'house',\n",
              " 'street_s',\n",
              " 'neck',\n",
              " 'blurriness',\n",
              " 'door_frame',\n",
              " 'eyebrow',\n",
              " 'bumper',\n",
              " 'muzzle',\n",
              " 'light',\n",
              " 'bathtub',\n",
              " 'faucet',\n",
              " 'fabric',\n",
              " 'bush',\n",
              " 'fan',\n",
              " 'leather',\n",
              " 'floor',\n",
              " 'bedroom_s',\n",
              " 'snow',\n",
              " 'knob',\n",
              " 'counter',\n",
              " 'canopy',\n",
              " 'bicycle',\n",
              " 'arm',\n",
              " 'beak',\n",
              " 'bannister',\n",
              " 'mountain',\n",
              " 'computer',\n",
              " 'blackness',\n",
              " 'ashcan',\n",
              " 'bag',\n",
              " 'refrigerator',\n",
              " 'blueness',\n",
              " 'horse',\n",
              " 'engine',\n",
              " 'stairs',\n",
              " 'bottle',\n",
              " 'cow',\n",
              " 'base',\n",
              " 'back_pillow',\n",
              " 'hair',\n",
              " 'keyboard',\n",
              " 'clock',\n",
              " 'palm',\n",
              " 'building',\n",
              " 'door',\n",
              " 'mirror',\n",
              " 'sand']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concept_bank.concept_info.concept_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "analyze_classifier(pcbm.model, class_names=)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
